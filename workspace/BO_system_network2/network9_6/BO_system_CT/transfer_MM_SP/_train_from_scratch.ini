[RUN]
#DEFAULT values will be applied, unless otherwise specified.
training_target_file_name = transfer_MM_SP/observed_target.csv
input_features_file_name = transfer_MM_SP/observed_input_features.csv
input_features_have_header = False
epochs = 100
target_list = [0,0] # Which feature of observed_target.csv
model_save_name_prefix = transfer_MM_SP/model_pre-trained_
csv_save_name_prefix = transfer_MM_SP/predicted_pre-trained_

# Manual normalization
output_manual_normalization = True
output_mean = [48.843254, 48.843254]
output_deviation = [102.01634, 102.01634]

[DEFAULT]
training_target_file_name = training_target.csv
input_features_file_name = input_features.csv
input_features_have_header = False

random_initial = 0 
mix_random_seed = 0
length_of_random_seed_text = 3
do_not_shuffle = False
target_list = [0, 2]

output_normalization = True
output_manual_normalization = False
output_mean = [0.5041992, 48.843254]
output_deviation = [0.5738414, 102.01634]
# Mean and standard deviation of the 0th and 6th features in the full dataset
#In case of multiple outputs

#output_mean = [48.843254]
#output_deviation = [102.01634]
#In case of single output

test_set_ratio = 0.2
n_test = 0

number_of_neurons_list = [100, 100, 10]
l2_scale = 0.001
epochs = 2000
patience_epochs = 100
batch_size = 8
learning_rate = 0.0005
validation_split = 0.2

number_of_ensemble = 10
save_model = True
model_save_name_prefix = model_
save_csv = True
csv_save_name_prefix = predicted_

memory_limit_gb = 2.0
